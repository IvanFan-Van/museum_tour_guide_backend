{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b93f074",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from pathlib import Path\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "stopword_corpus = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def preprocess_fn(text: str):\n",
    "    text = text.lower()\n",
    "    text = ''.join([c for c in text if c not in string.punctuation])\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [t for t in tokens if t not in stopword_corpus]\n",
    "    tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
    "    return tokens\n",
    "\n",
    "docs_folder = Path(\n",
    "    r\"D:\\HKU\\Inno Wing RA\\UBC Exchange\\code\\output\\Objectifying_China\\docs\"\n",
    ")\n",
    "loader = DirectoryLoader(str(docs_folder.absolute()), glob=\"**/*.md\", loader_cls=TextLoader, loader_kwargs={\"encoding\": \"utf-8\"})\n",
    "docs = loader.load()\n",
    "retriever = BM25Retriever.from_documents(docs, preprocess_func=preprocess_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50aa7a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='yes'\n"
     ]
    }
   ],
   "source": [
    "### Retrieval Grader\n",
    "import os\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Data model\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "# LLM with function call\n",
    "llm = AzureChatOpenAI(\n",
    "    api_version=os.environ[\"AZURE_API_VERSION\"],\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYEMENT\"]\n",
    ")\n",
    "\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "    It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "    If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\"\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "retrieval_grader = grade_prompt | structured_llm_grader\n",
    "question = \"Introduce to me some vases\"\n",
    "docs = retriever.invoke(question)\n",
    "doc_txt = docs[1].page_content\n",
    "print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61559fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are examples of vases:\n",
      "\n",
      "1. Longquan celadon vases were highly valued in East Asia, particularly in Japan, known for their translucent glaze and mallet shapes, often used for burial purposes during the Southern Song and Yuan dynasties.\n",
      "\n",
      "2. Mounted porcelain vases and bowls from Jingdezhen, China (Kangxi period), featured intricate designs like pierced \"linglong\" patterns and were later adorned with precious metal mounts in Europe to demonstrate wealth.\n",
      "\n",
      "These highlight the cultural significance and craftsmanship of vases across civilizations.\n"
     ]
    }
   ],
   "source": [
    "### Generate\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Prompt\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Chain\n",
    "rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Run\n",
    "generation = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b83fb833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradeHallucinations(binary_score='yes')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Hallucination Grader\n",
    "\n",
    "\n",
    "# Data model\n",
    "class GradeHallucinations(BaseModel):\n",
    "    \"\"\"Binary score for hallucination present in generation answer.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Answer is grounded in the facts, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "# LLM with function call\n",
    "structured_llm_grader = llm.with_structured_output(GradeHallucinations)\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"You are a grader assessing whether an LLM generation is grounded in / supported by a set of retrieved facts. \\n \n",
    "     Give a binary score 'yes' or 'no'. 'Yes' means that the answer is grounded in / supported by the set of facts.\"\"\"\n",
    "hallucination_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Set of facts: \\n\\n {documents} \\n\\n LLM generation: {generation}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "hallucination_grader = hallucination_prompt | structured_llm_grader\n",
    "hallucination_grader.invoke({\"documents\": docs, \"generation\": generation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "796d67f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradeAnswer(binary_score='yes')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Answer Grader\n",
    "\n",
    "\n",
    "# Data model\n",
    "class GradeAnswer(BaseModel):\n",
    "    \"\"\"Binary score to assess answer addresses question.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Answer addresses the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "# LLM with function call\n",
    "structured_llm_grader = llm.with_structured_output(GradeAnswer)\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"You are a grader assessing whether an answer addresses / resolves a question \\n \n",
    "     Give a binary score 'yes' or 'no'. Yes' means that the answer resolves the question.\"\"\"\n",
    "answer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"User question: \\n\\n {question} \\n\\n LLM generation: {generation}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "answer_grader = answer_prompt | structured_llm_grader\n",
    "answer_grader.invoke({\"question\": question, \"generation\": generation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "751d2f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Can you suggest different types or styles of vases and their unique features?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Question Re-writer\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"You a question re-writer that converts an input question to a better version that is optimized \\n \n",
    "     for vectorstore retrieval. Look at the input and try to reason about the underlying semantic intent / meaning.\"\"\"\n",
    "re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Here is the initial question: \\n\\n {question} \\n Formulate an improved question.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_rewriter = re_write_prompt | llm | StrOutputParser()\n",
    "question_rewriter.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ccdbbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        question: question\n",
    "        generation: LLM generation\n",
    "        documents: list of documents\n",
    "    \"\"\"\n",
    "\n",
    "    question: str\n",
    "    generation: str\n",
    "    documents: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b175e283",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Nodes\n",
    "\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    Retrieve documents\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    print(\"---RETRIEVE---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Retrieval\n",
    "    documents = retriever.invoke(question)\n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # RAG generation\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    return {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
    "\n",
    "\n",
    "def grade_documents(state):\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates documents key with only filtered relevant documents\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Score each doc\n",
    "    filtered_docs = []\n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke(\n",
    "            {\"question\": question, \"document\": d.page_content}\n",
    "        )\n",
    "        grade = score.binary_score\n",
    "        if grade == \"yes\":\n",
    "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "            continue\n",
    "    return {\"documents\": filtered_docs, \"question\": question}\n",
    "\n",
    "\n",
    "def transform_query(state):\n",
    "    \"\"\"\n",
    "    Transform the query to produce a better question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates question key with a re-phrased question\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---TRANSFORM QUERY---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    # Re-write question\n",
    "    better_question = question_rewriter.invoke({\"question\": question})\n",
    "    return {\"documents\": documents, \"question\": better_question}\n",
    "\n",
    "\n",
    "### Edges\n",
    "\n",
    "\n",
    "def decide_to_generate(state):\n",
    "    \"\"\"\n",
    "    Determines whether to generate an answer, or re-generate a question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Binary decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---ASSESS GRADED DOCUMENTS---\")\n",
    "    state[\"question\"]\n",
    "    filtered_documents = state[\"documents\"]\n",
    "\n",
    "    if not filtered_documents:\n",
    "        # All documents have been filtered check_relevance\n",
    "        # We will re-generate a new query\n",
    "        print(\n",
    "            \"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\"\n",
    "        )\n",
    "        return \"transform_query\"\n",
    "    else:\n",
    "        # We have relevant documents, so generate answer\n",
    "        print(\"---DECISION: GENERATE---\")\n",
    "        return \"generate\"\n",
    "\n",
    "\n",
    "def grade_generation_v_documents_and_question(state):\n",
    "    \"\"\"\n",
    "    Determines whether the generation is grounded in the document and answers question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK HALLUCINATIONS---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = state[\"generation\"]\n",
    "\n",
    "    score = hallucination_grader.invoke(\n",
    "        {\"documents\": documents, \"generation\": generation}\n",
    "    )\n",
    "    grade = score.binary_score\n",
    "\n",
    "    # Check hallucination\n",
    "    if grade == \"yes\":\n",
    "        print(\"---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\")\n",
    "        # Check question-answering\n",
    "        print(\"---GRADE GENERATION vs QUESTION---\")\n",
    "        score = answer_grader.invoke({\"question\": question, \"generation\": generation})\n",
    "        grade = score.binary_score\n",
    "        if grade == \"yes\":\n",
    "            print(\"---DECISION: GENERATION ADDRESSES QUESTION---\")\n",
    "            return \"useful\"\n",
    "        else:\n",
    "            print(\"---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\")\n",
    "            return \"not useful\"\n",
    "    else:\n",
    "        pprint(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\")\n",
    "        return \"not supported\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c920a4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"retrieve\", retrieve)  # retrieve\n",
    "workflow.add_node(\"grade_documents\", grade_documents)  # grade documents\n",
    "workflow.add_node(\"generate\", generate)  # generate\n",
    "workflow.add_node(\"transform_query\", transform_query)  # transform_query\n",
    "\n",
    "# Build graph\n",
    "workflow.add_edge(START, \"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"transform_query\": \"transform_query\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"transform_query\", \"retrieve\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate\",\n",
    "    grade_generation_v_documents_and_question,\n",
    "    {\n",
    "        \"not supported\": \"generate\",\n",
    "        \"useful\": END,\n",
    "        \"not useful\": \"transform_query\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# Compile\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44720439",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from pinecone_text.sparse import BM25Encoder\n",
    "from langchain_community.retrievers import PineconeHybridSearchRetriever\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# create the index\n",
    "index_name = \"umag-hybrid-search\"\n",
    "pc = Pinecone(api_key=os.environ.get(\"PINECONE_API_KEY\"))\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=3072,  # dimensionality of dense model\n",
    "        metric=\"dotproduct\",  # sparse values supported only for dotproduct\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "    )\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "bm25_encoder = BM25Encoder.default()\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\"],\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_EMBEDDING_ENDPOINT\"],\n",
    ")\n",
    "\n",
    "retriever = PineconeHybridSearchRetriever(\n",
    "    embeddings=embeddings, sparse_encoder=bm25_encoder, index=index, top_k=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb428a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from pathlib import Path\n",
    "\n",
    "docs_folder = Path(\n",
    "    r\"D:\\HKU\\Inno Wing RA\\UBC Exchange\\code\\output\\Objectifying_China\\docs\"\n",
    ")\n",
    "loader = DirectoryLoader(\n",
    "    str(docs_folder.absolute()),\n",
    "    glob=\"**/*.md\",\n",
    "    loader_cls=TextLoader,\n",
    "    loader_kwargs={\"encoding\": \"utf-8\"},\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "101eaa74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b6ed5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:16<00:00,  2.75s/it]\n"
     ]
    }
   ],
   "source": [
    "retriever.add_texts([\n",
    "    d.page_content for d in docs\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f0a0e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'score': 0.456929594}, page_content='![](https://cdn-mineru.openxlab.org.cn/result/2025-07-27/26ec8c02-599c-4b79-9876-e092d6287e02/0135e38ba2b52933cfe06032bd440b643e0ea5f7622891c690c30c256dec39f8.jpg)  \\n\\nPlate, Jingdezhen, China, 1739- 1743. Porcelain with overglaze enamels, diameter  $22.9 \\\\mathrm{~cm}$ . The Metropolitan Museum of Art, New York  碟·中國景德鎮·一七三九年至一七四三年·釉上彩瓷，直徑22.9厘米。紐約，大都會藝術博物館  '),\n",
       " Document(metadata={'score': 0.442890882}, page_content='![](https://cdn-mineru.openxlab.org.cn/result/2025-07-27/26ec8c02-599c-4b79-9876-e092d6287e02/6287610049ad775024f987714a2df9afac918f938997e628dbc261362ba0ff5b.jpg)  \\n\\njug with Portuguese arms. Jingdezhen, China, ca. 1520- 1540. Porcelain with underglaze blue, height  $18.7 \\\\mathrm{~cm}$ . The Metropolitan Museum of Art, New York  箱莓牙徽章纹壶·中國景德鎮·約一五二零年至一五四零年，青花瓷，高18.7厘米。紐約，大都會藝術博物館  '),\n",
       " Document(metadata={'score': 0.39922142}, page_content=\"# Tankard  \\n\\nJingdezhen, China (Ming dynasty), early 15th century Porcelain with underglaze blue, height  $13.3\\\\mathrm{cm}$  HKU.C.1957.0193  \\n\\nThe unusual shape of this tankard derives from containers introduced to China by traders from the Islamic world during the Yuan dynasty. The same form, but lacking a handle, is known in twelfth, thirteenth- and fourteenth- century Islamic metalwork, while examples with handles appear in Persian and Persian dynasty 479. Chinese metal work is often featured in the Yuan dynasty at the imperial kiln complex in Jingdezhen.  \\n\\nSuccessful both domestically and as export items sent to the Middle East, the continued to be produced into the reigns of the Yongle and Xuande emperors. Clearly treasured possessions in successive dynasties, a similar tankard displayed on a wooden stand is illustrated in the gw wan tu (pictures of ancient playthings') handscroll in the Victoria and Albert Museum; a form of pictorial inventory of the palace collections made in 1729 for the Yongzheng emperor.  \\n\\nEuropeans admired the exotic profiles of Chinese porcelains inspired by objects from the Middle East. After arriving in Europe, often via the Netherlands, tankards were sometimes mounted with silver- gilt covers and stands. Later on, seventeenth- century versions of these tankards from Arita were even made with pre- formed holes in the handles to facilitate the addition of mounts.\"),\n",
       " Document(metadata={'score': 0.399200618}, page_content=\"# Mounted bowl  \\n\\nJingdezhen, China, Kangxi period, 1662- 1722; mounts added in the Netherlands, late 17th century Porcelain with underglaze blue and ormolu mounts, 15.2 x 21.5 cm Asian Civilisations Museum, 2014- 00433  \\n\\nExotic and highly valued, early porcelain in Europe was perceived in the same way as natural curiosities like ostrich eggs, serpentine and coconuts, and like those materials was sometimes ornamented with expensive mounts chosen to enhance its value. Because of their rarity and cost, these early mounted porcelains were confined to royalty and a few aristocratic families, where they were used as attractive sideboards or displayed in kunstkammer (cabinets of curiosities in German).  \\n\\nAfter the Dutch and British East India companies entered the trade in Chinese ceramics in the seventeenth century, and porcelain became available to a growing middle- class, the practice of mounting these objects with precious metals continued as a means of demonstrating wealth and luxury. Their presence in numerous Dutch and Flemish still life paintings of the early seventeenth century attests to their popularity.  \\n\\nMounted porcelain took various forms, from small blue- and- white bowls and ewers to large celadon vases and pots. This bowl was made for export at Jingdezhen, with the mounts added later, probably in the Netherlands. The exterior features an openwork honeycomb and flower- head pattern, revealing a body decorated with underglaze blue floral sprays beneath. Double- walled objects with a pierced outer wall like this bowl are called linglong (devil's work') in China due to the time and effort it takes to produce them.\"),\n",
       " Document(metadata={'score': 0.390698433}, page_content=\"# Blanc de Chine\\n\\nThe extremely fine, evenly toned porcelains in this section were made in the kilns of Dehua in Fujian province, southern China. Fujian, a tea- growing region, attracted the attention of European merchants in the sixteenth and seventeenth centuries, and many of these objects were brought back to Europe, where this type of white Dehua porcelain became known as blanc de Chine (French for 'white of China'). They were also exported to Japan in large quantities.  \\n\\nDehua specialised in whitewares, the most highly prized were those with an ivory- coloured glaze. References in seventeenth century literary sources note that the translucent appearance of Dehua whitewares was the result of 'truly fine' porcelain stone that was dug by driving a shaft into the side of a nearby hill, from where the material was then pulled out with a rope. The earliest pieces of Dehua porcelain were made of this locally mined porcelain stone, with little or no clay, and were thinly potted. Unlike Jingdezhen, the Dehua kilns had no access to water transportation and until the arrival of foreign merchants most of its products were sold locally.  \\n\\nThe most common types of Dehua products were incense burners and Buddhist figures moulded and finished by hand. In China, these were usually placed on household altars and the latter were worshipped as devotional images. They were also brought to Europe as exotic curiosity items during the seventeenth century, where they were placed on tables and cabinets in the residences of aristocrats and wealthy people, or exhibited in porcelain rooms.  \\n\\nBy the eighteenth century, Europeans were familiar with Chinese polychrome ceramics. Dehua wares simply may have been seen as too plain by comparison, and many were gilded or enamelled in Europe to make them more attractive to customers. The Dehua kilns also produced objects tailored for the European market, including figures of Dutch men and women and Christian figures. These wares were closely copied at European porcelain factories, such as Meissen, Chantilly and Bow.  \"),\n",
       " Document(metadata={'score': 0.389505}, page_content=\"# Bowl with brown glaze  \\n\\nJingdezhen, China (Qing dynasty), Qianlong period, 1736- 1795 Porcelain with underglaze blue and brown glaze, diameter 18.5 cm HKUC.1987.0914  \\n\\nLarge quantities of bowls and dishes with underglaze blue decoration on the interior and deep brown glazes on the exterior were produced in Jingdezhen during the early eighteenth century, when the fashion for Chinese porcelain was at its highest in Europe. Made by adding high concentrations of iron oxide (usually in the form of iron filings) to the glaze during the firing process, porcelain wares of this type were referred to as Batavian ware, after the major Dutch port in Indonesia through which they were shipped.  \\n\\nA visitor to the Qing court, the French Jesuit priest Francois Xavier d'Entrecolles described porcelains of this type as tse- kin (golden brown) in letters sent to his superiors in 1712 and 1723. He observed that they were on the main wares manufactured for the Qing court on a regular basis, and a recent invention—though the long history of brown glazes in China suggests that he was referring specifically to technical processes used in the early eighteenth century rather than brown- glazed porcelain in general.  \\n\\nThese wares were particularly popular in the Netherlands, although significant quantities recovered from the foundered Swedish East Indiaman Gothervg (sunk 1745) demonstrate that they were also exported to Northern Europe in large quantities. They were shipped to America after it entered the China trade in 1784, and the decoration was later revived in the early nineteenth century, primarily on wares intended for export to Southeast Asia. This bowl was recovered from the Nanking cargo, the wreck of a Dutch East India Company ship which left Canton in December 1751 with more than 230,000 pieces of porcelain, textiles and tea for the European market.\"),\n",
       " Document(metadata={'score': 0.388110787}, page_content='# Vase  \\n\\nVaseJingdezhen, China (Qing dynasty) Kangxi period, 1662–1722Porcelain with overglaze enamels, height 45 cmHKU.C.1955.0172\\n\\n# Vase  \\n\\nJingdezhen, China (Qing dynasty) Kangxi period, 1662–1722Porcelain with overglaze enamels, height 48.2 cmHKU.C.1972.0437  \\n\\nThe pictorial decoration on these objects resembles literati- style landscape paintings. Incredibly detailed, the designs demonstrate the sophisticated porcelain enamelling techniques developed during the reign of the Kangxi emperor. A great supporter of the arts, Kangxi initiated major efforts to rebuild the kilns at Jingdezhen, which had been destroyed in 1674 by Minna rebels. The emperor encouraged potters at the newly- rebuilt kilns to push technological limits, resulting in large, finely potted ceramics with complex polychrome designs.  \\n\\nCommon subjects for such objects include historical characters modelled after illustrations in woodblock- print plays and novels. Literati themes were also popular, such as the scene of scholars enjoying leisurely activities depicted on the brush pot, or the scholarly objects and antiques depicted in panels on the second vase.\\n\\n# Brush pot  \\n\\nBrush potJingdezhen, China (Qing dynasty) Kangxi period, 1662–1722Porcelain with underglaze blue and overglaze enamels, height 16.9 cmHKU.C.1972.0431'),\n",
       " Document(metadata={'score': 0.385866076}, page_content=\"# Vase and plate  \\n\\nJingdezhen, China (Qing dynasty) Kangxi period, 1662- 1722 Porcelain with powder blue glaze, gilding and overglaze enamels, height  $43.3\\\\mathrm{cm}$  diameter  $27~\\\\mathrm{cm}$  HKU.C.1954.0136, HKU.C.1976.0623  \\n\\nThe speckled blue surface of these objects, called powder blue, was created by blowing cobalt blue through a bamboo tube onto unfired porcelain, a technique that was perfected in the Kangxi period. On wares like this, specially shaped resists were used to create blank areas, which were subsequently painted in overglaze enamels and then fired a second time. A third firing fixed gilded designs onto the surface of the blue ground.  \\n\\nThe complex three- stage decoration and firing of such objects made them luxurious and expensive export items. They were often decorated with figure and objects that European consumers found appealing, such as a slender Chinese lady depicted in several panels on the vase. In the Dutch language she was called Lange Lijs, which became 'Long Eliza' in English. One of the most popular designs on export wares from the Kangxi period, the design was widely imitated in European porcelain, particularly on plates and bowls from Worcester in the 1760s.\"),\n",
       " Document(metadata={'score': 0.384547293}, page_content='# Pair of plates with wucai enamels  \\n\\nJingdezhen, China (Ming dynasty), Wanli period, 1573- 1620 Porcelain with underglaze blue and overglaze enamels, diameter 11 cm HKUC.1959.0278  \\n\\nThese ceramics are decorated in the wucai (five- colour) palette, with outlines in underglaze blue and surface enamels in red, yellow and green. First developed during the reign of the Jiajing emperor, the production of wucai porcelain flourished in the Wanli period. These emperors commissioned a variety of porcelain objects decorated in this style, made in both the imperial kilns and private commercial enterprises. These plates, decorated on the interior with an imperial five- clawed dragon and marked on the base with the reign marks of the Wanli emperor, may be one such example.  \\n\\nDespite the name, wucai porcelain could be decorated with fewer or more than five colours. Ming dynasty enamelling techniques allowed for some variety in tone, but gradations in colour and shading were limited. Innovations in the Kangsi period, such as the addition of opaque white (derived from lead arsenate) and transparent ruby enamel (from colloidal gold), led to the development of new variations of wucai, such as famille rose, which were highly prized in Europe.'),\n",
       " Document(metadata={'score': 0.382969439}, page_content='# Bowl  \\n\\nJingdezhen, China (Ming dynasty), early or mid- 15th century Porcelain with underglaze blue, diameter 20.8 cm HKU.C.2003.1485  \\n\\nThe base of this bowl is painted with the reign marks of the Xuande emperor, but in its shape and design it is closely related to a group of Chenghua period blue- and- white porcelain bowls formerly in the collection of the Tsui Museum of Art. The Tsui bowls are similarly marked Xuande, but were unearthed from Chenghua period strata at imperial kiln sites in Jingdezhen. They represent the earliest known examples of reign marks from a previous era being inscribed on pieces of imperial porcelain—a practice that later became widespread as a mark of respect and to acknowledge the borrowing of designs. Lions playing with beribboned balls on the exterior carry auspicious associations of physical and spiritual power and wishes for high rank.\\n\\n8. The Tsui Museum of Art housed the collection of Hong Kong businessman T.T. Tsui, who began collecting in the 1970s. Tsui donated a significant portion of his collection to UMAG and the Hong Kong Heritage Museum, as well as to numerous institutions in Australia, the United Kingdom and the United States.  \\n')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"Please introduce some Jingdezhen porcelains\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
